{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Skt_i73Mz32B",
        "outputId": "d9c613fa-889e-45ba-e744-0c3b5cbeec70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /user/HS400/rl01179/.local/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /user/HS400/rl01179/.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /user/HS400/rl01179/.local/lib/python3.10/site-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /user/HS400/rl01179/.local/lib/python3.10/site-packages (from datasets) (2025.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Collecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess<0.70.17\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /user/HS400/rl01179/.local/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting propcache>=0.2.0\n",
            "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.0 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OyYDA2N5jaS3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LotoArojjnG0",
        "outputId": "ef77bc27-76f8-4eaf-b749-162c27966662"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hCyeGJGi17A4"
      },
      "outputs": [],
      "source": [
        "labels = [\"O\", \"B-AC\", \"B-LF\", \"I-LF\"]\n",
        "n_labels = len(labels)\n",
        "ltoi = {l: i for i, l in enumerate(labels)}\n",
        "itol = {i: l for l, i in ltoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ub4Xj1emF83",
        "outputId": "54e1af23-21ac-4256-c684-47cde0321679"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01996fd953fc4362b8df7d48cb1101a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71b61d72ad3a4757bd4a75ca0c3fc72b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "887bcb81350f4d99969b2b8f2df984d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\" # Or deberta-v3-large, etc.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Check if the tokenizer is a fast tokenizer (it should be for DeBERTa-v3)\n",
        "assert tokenizer.is_fast, \"Only fast tokenizers are supported for this example.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oi_28FRemLiH"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True, # Crucial for pre-tokenized input\n",
        "        max_length=512,\n",
        "        padding=\"max_length\"\n",
        "\n",
        "    )\n",
        "\n",
        "    labels = []\n",
        "    for i, label_sequence in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None: # Special tokens ([CLS], [SEP])\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx: # First token of a new word\n",
        "                label_ids.append(ltoi[label_sequence[word_idx]])\n",
        "            else: # Subsequent tokens of the same word\n",
        "                label_ids.append(-100)\n",
        "\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33SKzjqI2-5t",
        "outputId": "2ea73f15-721f-462f-fcb7-8442255988f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1, 4146, 519, 58917, 407, 107679, 2]]\n",
            "[None, 0, 1, 2, 2, 3, None]\n"
          ]
        }
      ],
      "source": [
        "t = tokenizer([\"Pakistan got nuked lmao\"])\n",
        "print(t.input_ids)\n",
        "print(t.word_ids(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FvgTr0TQ2kiY"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "103fe5aabde148d58b0858f76a9541c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec9ee6d3514c4160afb33da2c728f06c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd19a0d763804a8b8d74ed8ea7914c7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = dataset.map(tokenize_and_align_labels, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AyYEqraW4PxD"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels, train_attention_mask = data['train']['input_ids'], data['train']['labels'], data['train']['attention_mask']\n",
        "val_data, val_labels, val_attention_mask = data['validation']['input_ids'], data['validation']['labels'], data['validation']['attention_mask']\n",
        "test_data, test_labels, test_attention_mask = data['test']['input_ids'], data['test']['labels'], data['test']['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CUuL3NNq4x2S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 8\n",
        "\n",
        "def get_batch(split = \"train\"):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  labels = train_labels if split == \"train\" else val_labels\n",
        "  attention_mask = train_attention_mask if split == \"train\" else val_attention_mask\n",
        "  ix = torch.randint(len(data), (batch_size,))\n",
        "  x = torch.stack([torch.tensor(data[i]).long() for i in ix])\n",
        "  y = torch.stack([torch.tensor(labels[i]).long() for i in ix])\n",
        "  a = torch.stack([torch.tensor(attention_mask[i]) for i in ix])\n",
        "  return x.to(device), y.to(device), a.to(device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(eval_steps):\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in [\"train\", \"validation\"]:\n",
        "    losses = torch.zeros(eval_steps)\n",
        "    for k in range(eval_steps):\n",
        "      x, y, a = get_batch(split)\n",
        "      logits = model(x, attention_mask = a).logits\n",
        "      loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision(\"high\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9-2-KcIpMGK",
        "outputId": "825c5e14-26d8-4a11-867f-7178e4837b41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dfe7d6ede614a5797bffe924a127629",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be968875894c4c58949d23d78003d60c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=n_labels,\n",
        "    id2label=itol,\n",
        "    label2id=ltoi\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.0000e-06, 1.0046e-06, 1.0093e-06, 1.0139e-06, 1.0186e-06, 1.0233e-06,\n",
            "        1.0280e-06, 1.0328e-06, 1.0376e-06, 1.0424e-06, 1.0472e-06, 1.0520e-06,\n",
            "        1.0569e-06, 1.0618e-06, 1.0667e-06, 1.0716e-06, 1.0765e-06, 1.0815e-06,\n",
            "        1.0865e-06, 1.0915e-06, 1.0966e-06, 1.1016e-06, 1.1067e-06, 1.1119e-06,\n",
            "        1.1170e-06, 1.1221e-06, 1.1273e-06, 1.1325e-06, 1.1378e-06, 1.1430e-06,\n",
            "        1.1483e-06, 1.1536e-06, 1.1589e-06, 1.1643e-06, 1.1697e-06, 1.1751e-06,\n",
            "        1.1805e-06, 1.1860e-06, 1.1915e-06, 1.1970e-06, 1.2025e-06, 1.2080e-06,\n",
            "        1.2136e-06, 1.2192e-06, 1.2249e-06, 1.2305e-06, 1.2362e-06, 1.2419e-06,\n",
            "        1.2477e-06, 1.2534e-06, 1.2592e-06, 1.2650e-06, 1.2709e-06, 1.2768e-06,\n",
            "        1.2826e-06, 1.2886e-06, 1.2945e-06, 1.3005e-06, 1.3065e-06, 1.3126e-06,\n",
            "        1.3186e-06, 1.3247e-06, 1.3308e-06, 1.3370e-06, 1.3432e-06, 1.3494e-06,\n",
            "        1.3556e-06, 1.3619e-06, 1.3682e-06, 1.3745e-06, 1.3808e-06, 1.3872e-06,\n",
            "        1.3936e-06, 1.4001e-06, 1.4065e-06, 1.4130e-06, 1.4196e-06, 1.4261e-06,\n",
            "        1.4327e-06, 1.4393e-06, 1.4460e-06, 1.4527e-06, 1.4594e-06, 1.4661e-06,\n",
            "        1.4729e-06, 1.4797e-06, 1.4865e-06, 1.4934e-06, 1.5003e-06, 1.5072e-06,\n",
            "        1.5142e-06, 1.5212e-06, 1.5282e-06, 1.5353e-06, 1.5424e-06, 1.5495e-06,\n",
            "        1.5567e-06, 1.5638e-06, 1.5711e-06, 1.5783e-06, 1.5856e-06, 1.5930e-06,\n",
            "        1.6003e-06, 1.6077e-06, 1.6151e-06, 1.6226e-06, 1.6301e-06, 1.6376e-06,\n",
            "        1.6452e-06, 1.6528e-06, 1.6604e-06, 1.6681e-06, 1.6758e-06, 1.6836e-06,\n",
            "        1.6913e-06, 1.6991e-06, 1.7070e-06, 1.7149e-06, 1.7228e-06, 1.7308e-06,\n",
            "        1.7388e-06, 1.7468e-06, 1.7549e-06, 1.7630e-06, 1.7711e-06, 1.7793e-06,\n",
            "        1.7875e-06, 1.7958e-06, 1.8041e-06, 1.8124e-06, 1.8208e-06, 1.8292e-06,\n",
            "        1.8377e-06, 1.8461e-06, 1.8547e-06, 1.8632e-06, 1.8719e-06, 1.8805e-06,\n",
            "        1.8892e-06, 1.8979e-06, 1.9067e-06, 1.9155e-06, 1.9244e-06, 1.9332e-06,\n",
            "        1.9422e-06, 1.9511e-06, 1.9602e-06, 1.9692e-06, 1.9783e-06, 1.9875e-06,\n",
            "        1.9966e-06, 2.0059e-06, 2.0151e-06, 2.0244e-06, 2.0338e-06, 2.0432e-06,\n",
            "        2.0526e-06, 2.0621e-06, 2.0716e-06, 2.0812e-06, 2.0908e-06, 2.1005e-06,\n",
            "        2.1102e-06, 2.1200e-06, 2.1297e-06, 2.1396e-06, 2.1495e-06, 2.1594e-06,\n",
            "        2.1694e-06, 2.1794e-06, 2.1895e-06, 2.1996e-06, 2.2098e-06, 2.2200e-06,\n",
            "        2.2302e-06, 2.2405e-06, 2.2509e-06, 2.2613e-06, 2.2717e-06, 2.2822e-06,\n",
            "        2.2928e-06, 2.3034e-06, 2.3140e-06, 2.3247e-06, 2.3354e-06, 2.3462e-06,\n",
            "        2.3571e-06, 2.3680e-06, 2.3789e-06, 2.3899e-06, 2.4009e-06, 2.4120e-06,\n",
            "        2.4232e-06, 2.4344e-06, 2.4456e-06, 2.4569e-06, 2.4683e-06, 2.4797e-06,\n",
            "        2.4911e-06, 2.5026e-06, 2.5142e-06, 2.5258e-06, 2.5375e-06, 2.5492e-06,\n",
            "        2.5610e-06, 2.5728e-06, 2.5847e-06, 2.5967e-06, 2.6087e-06, 2.6207e-06,\n",
            "        2.6328e-06, 2.6450e-06, 2.6572e-06, 2.6695e-06, 2.6818e-06, 2.6942e-06,\n",
            "        2.7067e-06, 2.7192e-06, 2.7317e-06, 2.7443e-06, 2.7570e-06, 2.7698e-06,\n",
            "        2.7826e-06, 2.7954e-06, 2.8083e-06, 2.8213e-06, 2.8343e-06, 2.8474e-06,\n",
            "        2.8606e-06, 2.8738e-06, 2.8871e-06, 2.9004e-06, 2.9138e-06, 2.9273e-06,\n",
            "        2.9408e-06, 2.9544e-06, 2.9681e-06, 2.9818e-06, 2.9956e-06, 3.0094e-06,\n",
            "        3.0233e-06, 3.0373e-06, 3.0513e-06, 3.0654e-06, 3.0796e-06, 3.0938e-06,\n",
            "        3.1081e-06, 3.1224e-06, 3.1369e-06, 3.1514e-06, 3.1659e-06, 3.1806e-06,\n",
            "        3.1952e-06, 3.2100e-06, 3.2248e-06, 3.2397e-06, 3.2547e-06, 3.2697e-06,\n",
            "        3.2849e-06, 3.3000e-06, 3.3153e-06, 3.3306e-06, 3.3460e-06, 3.3614e-06,\n",
            "        3.3770e-06, 3.3926e-06, 3.4083e-06, 3.4240e-06, 3.4398e-06, 3.4557e-06,\n",
            "        3.4717e-06, 3.4877e-06, 3.5038e-06, 3.5200e-06, 3.5363e-06, 3.5526e-06,\n",
            "        3.5691e-06, 3.5855e-06, 3.6021e-06, 3.6187e-06, 3.6355e-06, 3.6523e-06,\n",
            "        3.6691e-06, 3.6861e-06, 3.7031e-06, 3.7202e-06, 3.7374e-06, 3.7547e-06,\n",
            "        3.7720e-06, 3.7895e-06, 3.8070e-06, 3.8246e-06, 3.8422e-06, 3.8600e-06,\n",
            "        3.8778e-06, 3.8957e-06, 3.9137e-06, 3.9318e-06, 3.9500e-06, 3.9682e-06,\n",
            "        3.9866e-06, 4.0050e-06, 4.0235e-06, 4.0421e-06, 4.0608e-06, 4.0795e-06,\n",
            "        4.0984e-06, 4.1173e-06, 4.1363e-06, 4.1555e-06, 4.1747e-06, 4.1939e-06,\n",
            "        4.2133e-06, 4.2328e-06, 4.2523e-06, 4.2720e-06, 4.2917e-06, 4.3116e-06,\n",
            "        4.3315e-06, 4.3515e-06, 4.3716e-06, 4.3918e-06, 4.4121e-06, 4.4325e-06,\n",
            "        4.4530e-06, 4.4735e-06, 4.4942e-06, 4.5150e-06, 4.5358e-06, 4.5568e-06,\n",
            "        4.5778e-06, 4.5990e-06, 4.6202e-06, 4.6416e-06, 4.6630e-06, 4.6846e-06,\n",
            "        4.7062e-06, 4.7280e-06, 4.7498e-06, 4.7718e-06, 4.7938e-06, 4.8160e-06,\n",
            "        4.8382e-06, 4.8606e-06, 4.8830e-06, 4.9056e-06, 4.9283e-06, 4.9510e-06,\n",
            "        4.9739e-06, 4.9969e-06, 5.0200e-06, 5.0432e-06, 5.0665e-06, 5.0899e-06,\n",
            "        5.1134e-06, 5.1370e-06, 5.1607e-06, 5.1846e-06, 5.2085e-06, 5.2326e-06,\n",
            "        5.2568e-06, 5.2811e-06, 5.3055e-06, 5.3300e-06, 5.3546e-06, 5.3794e-06,\n",
            "        5.4042e-06, 5.4292e-06, 5.4543e-06, 5.4795e-06, 5.5048e-06, 5.5302e-06,\n",
            "        5.5558e-06, 5.5814e-06, 5.6072e-06, 5.6331e-06, 5.6592e-06, 5.6853e-06,\n",
            "        5.7116e-06, 5.7380e-06, 5.7645e-06, 5.7911e-06, 5.8179e-06, 5.8448e-06,\n",
            "        5.8718e-06, 5.8989e-06, 5.9262e-06, 5.9535e-06, 5.9810e-06, 6.0087e-06,\n",
            "        6.0364e-06, 6.0643e-06, 6.0923e-06, 6.1205e-06, 6.1488e-06, 6.1772e-06,\n",
            "        6.2057e-06, 6.2344e-06, 6.2632e-06, 6.2921e-06, 6.3212e-06, 6.3504e-06,\n",
            "        6.3798e-06, 6.4092e-06, 6.4389e-06, 6.4686e-06, 6.4985e-06, 6.5285e-06,\n",
            "        6.5587e-06, 6.5890e-06, 6.6194e-06, 6.6500e-06, 6.6807e-06, 6.7116e-06,\n",
            "        6.7426e-06, 6.7738e-06, 6.8051e-06, 6.8365e-06, 6.8681e-06, 6.8998e-06,\n",
            "        6.9317e-06, 6.9637e-06, 6.9959e-06, 7.0282e-06, 7.0607e-06, 7.0933e-06,\n",
            "        7.1261e-06, 7.1590e-06, 7.1921e-06, 7.2254e-06, 7.2587e-06, 7.2923e-06,\n",
            "        7.3260e-06, 7.3598e-06, 7.3938e-06, 7.4280e-06, 7.4623e-06, 7.4968e-06,\n",
            "        7.5314e-06, 7.5662e-06, 7.6012e-06, 7.6363e-06, 7.6716e-06, 7.7070e-06,\n",
            "        7.7426e-06, 7.7784e-06, 7.8143e-06, 7.8505e-06, 7.8867e-06, 7.9232e-06,\n",
            "        7.9598e-06, 7.9966e-06, 8.0335e-06, 8.0706e-06, 8.1079e-06, 8.1454e-06,\n",
            "        8.1830e-06, 8.2208e-06, 8.2588e-06, 8.2970e-06, 8.3353e-06, 8.3738e-06,\n",
            "        8.4125e-06, 8.4514e-06, 8.4904e-06, 8.5296e-06, 8.5691e-06, 8.6087e-06,\n",
            "        8.6484e-06, 8.6884e-06, 8.7285e-06, 8.7689e-06, 8.8094e-06, 8.8501e-06,\n",
            "        8.8910e-06, 8.9320e-06, 8.9733e-06, 9.0148e-06, 9.0564e-06, 9.0983e-06,\n",
            "        9.1403e-06, 9.1825e-06, 9.2250e-06, 9.2676e-06, 9.3104e-06, 9.3534e-06,\n",
            "        9.3966e-06, 9.4401e-06, 9.4837e-06, 9.5275e-06, 9.5715e-06, 9.6157e-06,\n",
            "        9.6602e-06, 9.7048e-06, 9.7496e-06, 9.7947e-06, 9.8399e-06, 9.8854e-06,\n",
            "        9.9311e-06, 9.9770e-06, 1.0023e-05, 1.0069e-05, 1.0116e-05, 1.0163e-05,\n",
            "        1.0210e-05, 1.0257e-05, 1.0304e-05, 1.0352e-05, 1.0400e-05, 1.0448e-05,\n",
            "        1.0496e-05, 1.0544e-05, 1.0593e-05, 1.0642e-05, 1.0691e-05, 1.0741e-05,\n",
            "        1.0790e-05, 1.0840e-05, 1.0890e-05, 1.0941e-05, 1.0991e-05, 1.1042e-05,\n",
            "        1.1093e-05, 1.1144e-05, 1.1196e-05, 1.1247e-05, 1.1299e-05, 1.1352e-05,\n",
            "        1.1404e-05, 1.1457e-05, 1.1510e-05, 1.1563e-05, 1.1616e-05, 1.1670e-05,\n",
            "        1.1724e-05, 1.1778e-05, 1.1832e-05, 1.1887e-05, 1.1942e-05, 1.1997e-05,\n",
            "        1.2053e-05, 1.2108e-05, 1.2164e-05, 1.2220e-05, 1.2277e-05, 1.2334e-05,\n",
            "        1.2391e-05, 1.2448e-05, 1.2505e-05, 1.2563e-05, 1.2621e-05, 1.2680e-05,\n",
            "        1.2738e-05, 1.2797e-05, 1.2856e-05, 1.2915e-05, 1.2975e-05, 1.3035e-05,\n",
            "        1.3095e-05, 1.3156e-05, 1.3217e-05, 1.3278e-05, 1.3339e-05, 1.3401e-05,\n",
            "        1.3463e-05, 1.3525e-05, 1.3587e-05, 1.3650e-05, 1.3713e-05, 1.3777e-05,\n",
            "        1.3840e-05, 1.3904e-05, 1.3968e-05, 1.4033e-05, 1.4098e-05, 1.4163e-05,\n",
            "        1.4228e-05, 1.4294e-05, 1.4360e-05, 1.4426e-05, 1.4493e-05, 1.4560e-05,\n",
            "        1.4627e-05, 1.4695e-05, 1.4763e-05, 1.4831e-05, 1.4900e-05, 1.4968e-05,\n",
            "        1.5038e-05, 1.5107e-05, 1.5177e-05, 1.5247e-05, 1.5317e-05, 1.5388e-05,\n",
            "        1.5459e-05, 1.5531e-05, 1.5602e-05, 1.5675e-05, 1.5747e-05, 1.5820e-05,\n",
            "        1.5893e-05, 1.5966e-05, 1.6040e-05, 1.6114e-05, 1.6189e-05, 1.6263e-05,\n",
            "        1.6339e-05, 1.6414e-05, 1.6490e-05, 1.6566e-05, 1.6643e-05, 1.6719e-05,\n",
            "        1.6797e-05, 1.6874e-05, 1.6952e-05, 1.7031e-05, 1.7109e-05, 1.7188e-05,\n",
            "        1.7268e-05, 1.7348e-05, 1.7428e-05, 1.7508e-05, 1.7589e-05, 1.7670e-05,\n",
            "        1.7752e-05, 1.7834e-05, 1.7917e-05, 1.7999e-05, 1.8082e-05, 1.8166e-05,\n",
            "        1.8250e-05, 1.8334e-05, 1.8419e-05, 1.8504e-05, 1.8590e-05, 1.8675e-05,\n",
            "        1.8762e-05, 1.8848e-05, 1.8936e-05, 1.9023e-05, 1.9111e-05, 1.9199e-05,\n",
            "        1.9288e-05, 1.9377e-05, 1.9467e-05, 1.9557e-05, 1.9647e-05, 1.9738e-05,\n",
            "        1.9829e-05, 1.9920e-05, 2.0013e-05, 2.0105e-05, 2.0198e-05, 2.0291e-05,\n",
            "        2.0385e-05, 2.0479e-05, 2.0574e-05, 2.0669e-05, 2.0764e-05, 2.0860e-05,\n",
            "        2.0957e-05, 2.1053e-05, 2.1151e-05, 2.1248e-05, 2.1347e-05, 2.1445e-05,\n",
            "        2.1544e-05, 2.1644e-05, 2.1744e-05, 2.1844e-05, 2.1945e-05, 2.2047e-05,\n",
            "        2.2149e-05, 2.2251e-05, 2.2354e-05, 2.2457e-05, 2.2561e-05, 2.2665e-05,\n",
            "        2.2770e-05, 2.2875e-05, 2.2981e-05, 2.3087e-05, 2.3193e-05, 2.3301e-05,\n",
            "        2.3408e-05, 2.3516e-05, 2.3625e-05, 2.3734e-05, 2.3844e-05, 2.3954e-05,\n",
            "        2.4065e-05, 2.4176e-05, 2.4288e-05, 2.4400e-05, 2.4513e-05, 2.4626e-05,\n",
            "        2.4740e-05, 2.4854e-05, 2.4969e-05, 2.5084e-05, 2.5200e-05, 2.5316e-05,\n",
            "        2.5433e-05, 2.5551e-05, 2.5669e-05, 2.5788e-05, 2.5907e-05, 2.6026e-05,\n",
            "        2.6147e-05, 2.6268e-05, 2.6389e-05, 2.6511e-05, 2.6633e-05, 2.6756e-05,\n",
            "        2.6880e-05, 2.7004e-05, 2.7129e-05, 2.7254e-05, 2.7380e-05, 2.7507e-05,\n",
            "        2.7634e-05, 2.7762e-05, 2.7890e-05, 2.8019e-05, 2.8148e-05, 2.8278e-05,\n",
            "        2.8409e-05, 2.8540e-05, 2.8672e-05, 2.8804e-05, 2.8938e-05, 2.9071e-05,\n",
            "        2.9206e-05, 2.9340e-05, 2.9476e-05, 2.9612e-05, 2.9749e-05, 2.9887e-05,\n",
            "        3.0025e-05, 3.0163e-05, 3.0303e-05, 3.0443e-05, 3.0583e-05, 3.0725e-05,\n",
            "        3.0867e-05, 3.1009e-05, 3.1153e-05, 3.1296e-05, 3.1441e-05, 3.1586e-05,\n",
            "        3.1732e-05, 3.1879e-05, 3.2026e-05, 3.2174e-05, 3.2323e-05, 3.2472e-05,\n",
            "        3.2622e-05, 3.2773e-05, 3.2924e-05, 3.3076e-05, 3.3229e-05, 3.3383e-05,\n",
            "        3.3537e-05, 3.3692e-05, 3.3848e-05, 3.4004e-05, 3.4161e-05, 3.4319e-05,\n",
            "        3.4478e-05, 3.4637e-05, 3.4797e-05, 3.4958e-05, 3.5119e-05, 3.5282e-05,\n",
            "        3.5445e-05, 3.5608e-05, 3.5773e-05, 3.5938e-05, 3.6104e-05, 3.6271e-05,\n",
            "        3.6439e-05, 3.6607e-05, 3.6776e-05, 3.6946e-05, 3.7117e-05, 3.7288e-05,\n",
            "        3.7461e-05, 3.7634e-05, 3.7807e-05, 3.7982e-05, 3.8158e-05, 3.8334e-05,\n",
            "        3.8511e-05, 3.8689e-05, 3.8868e-05, 3.9047e-05, 3.9228e-05, 3.9409e-05,\n",
            "        3.9591e-05, 3.9774e-05, 3.9958e-05, 4.0142e-05, 4.0328e-05, 4.0514e-05,\n",
            "        4.0701e-05, 4.0890e-05, 4.1078e-05, 4.1268e-05, 4.1459e-05, 4.1650e-05,\n",
            "        4.1843e-05, 4.2036e-05, 4.2230e-05, 4.2426e-05, 4.2622e-05, 4.2819e-05,\n",
            "        4.3016e-05, 4.3215e-05, 4.3415e-05, 4.3615e-05, 4.3817e-05, 4.4019e-05,\n",
            "        4.4223e-05, 4.4427e-05, 4.4632e-05, 4.4839e-05, 4.5046e-05, 4.5254e-05,\n",
            "        4.5463e-05, 4.5673e-05, 4.5884e-05, 4.6096e-05, 4.6309e-05, 4.6523e-05,\n",
            "        4.6738e-05, 4.6954e-05, 4.7171e-05, 4.7389e-05, 4.7608e-05, 4.7828e-05,\n",
            "        4.8049e-05, 4.8271e-05, 4.8494e-05, 4.8718e-05, 4.8943e-05, 4.9169e-05,\n",
            "        4.9396e-05, 4.9624e-05, 4.9854e-05, 5.0084e-05, 5.0315e-05, 5.0548e-05,\n",
            "        5.0782e-05, 5.1016e-05, 5.1252e-05, 5.1489e-05, 5.1727e-05, 5.1966e-05,\n",
            "        5.2206e-05, 5.2447e-05, 5.2689e-05, 5.2933e-05, 5.3177e-05, 5.3423e-05,\n",
            "        5.3670e-05, 5.3918e-05, 5.4167e-05, 5.4417e-05, 5.4669e-05, 5.4921e-05,\n",
            "        5.5175e-05, 5.5430e-05, 5.5686e-05, 5.5943e-05, 5.6202e-05, 5.6461e-05,\n",
            "        5.6722e-05, 5.6984e-05, 5.7248e-05, 5.7512e-05, 5.7778e-05, 5.8045e-05,\n",
            "        5.8313e-05, 5.8583e-05, 5.8853e-05, 5.9125e-05, 5.9398e-05, 5.9673e-05,\n",
            "        5.9948e-05, 6.0225e-05, 6.0504e-05, 6.0783e-05, 6.1064e-05, 6.1346e-05,\n",
            "        6.1630e-05, 6.1914e-05, 6.2200e-05, 6.2488e-05, 6.2777e-05, 6.3067e-05,\n",
            "        6.3358e-05, 6.3651e-05, 6.3945e-05, 6.4240e-05, 6.4537e-05, 6.4835e-05,\n",
            "        6.5135e-05, 6.5436e-05, 6.5738e-05, 6.6042e-05, 6.6347e-05, 6.6654e-05,\n",
            "        6.6962e-05, 6.7271e-05, 6.7582e-05, 6.7894e-05, 6.8208e-05, 6.8523e-05,\n",
            "        6.8840e-05, 6.9158e-05, 6.9477e-05, 6.9798e-05, 7.0121e-05, 7.0445e-05,\n",
            "        7.0770e-05, 7.1097e-05, 7.1426e-05, 7.1756e-05, 7.2087e-05, 7.2420e-05,\n",
            "        7.2755e-05, 7.3091e-05, 7.3429e-05, 7.3768e-05, 7.4109e-05, 7.4451e-05,\n",
            "        7.4795e-05, 7.5141e-05, 7.5488e-05, 7.5837e-05, 7.6187e-05, 7.6539e-05,\n",
            "        7.6893e-05, 7.7248e-05, 7.7605e-05, 7.7964e-05, 7.8324e-05, 7.8686e-05,\n",
            "        7.9049e-05, 7.9415e-05, 7.9781e-05, 8.0150e-05, 8.0520e-05, 8.0892e-05,\n",
            "        8.1266e-05, 8.1642e-05, 8.2019e-05, 8.2398e-05, 8.2779e-05, 8.3161e-05,\n",
            "        8.3545e-05, 8.3931e-05, 8.4319e-05, 8.4709e-05, 8.5100e-05, 8.5493e-05,\n",
            "        8.5888e-05, 8.6285e-05, 8.6684e-05, 8.7084e-05, 8.7487e-05, 8.7891e-05,\n",
            "        8.8297e-05, 8.8705e-05, 8.9115e-05, 8.9527e-05, 8.9940e-05, 9.0356e-05,\n",
            "        9.0773e-05, 9.1193e-05, 9.1614e-05, 9.2037e-05, 9.2463e-05, 9.2890e-05,\n",
            "        9.3319e-05, 9.3750e-05, 9.4183e-05, 9.4618e-05, 9.5056e-05, 9.5495e-05,\n",
            "        9.5936e-05, 9.6379e-05, 9.6825e-05, 9.7272e-05, 9.7721e-05, 9.8173e-05,\n",
            "        9.8627e-05, 9.9082e-05, 9.9540e-05, 1.0000e-04])\n"
          ]
        }
      ],
      "source": [
        "lre =torch.linspace(-6, -4, 1000)\n",
        "lrs = 10**lre\n",
        "print(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr = 3e-5)\n",
        "max_steps = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEMcSmbW4y6j",
        "outputId": "cfd7ecc3-f7be-4a37-80a5-2c1fdcae8058"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]W0514 21:37:09.034000 3271872 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "  0%|          | 1/1000 [00:36<10:13:46, 36.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0: train loss 1.8617, val loss 1.8741\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 103/1000 [01:17<50:36,  3.39s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 100: train loss 0.1638, val loss 0.2421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 203/1000 [01:48<45:42,  3.44s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 200: train loss 0.1701, val loss 0.2437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 303/1000 [02:19<40:12,  3.46s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 300: train loss 0.1289, val loss 0.2315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 403/1000 [02:50<34:31,  3.47s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 400: train loss 0.1132, val loss 0.2309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 503/1000 [03:22<28:49,  3.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 500: train loss 0.1007, val loss 0.2348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 603/1000 [03:53<23:02,  3.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 600: train loss 0.0836, val loss 0.2710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 703/1000 [04:25<17:14,  3.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 700: train loss 0.0817, val loss 0.3079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 803/1000 [04:56<11:26,  3.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 800: train loss 0.0643, val loss 0.2518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 903/1000 [05:27<05:37,  3.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 900: train loss 0.0532, val loss 0.2718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [05:38<00:00,  2.96it/s]\n"
          ]
        }
      ],
      "source": [
        "lossi = []\n",
        "lri = []\n",
        "\n",
        "for step in tqdm(range(max_steps)):\n",
        "  # for g in optim.param_groups:\n",
        "  #   g['lr'] = lrs[step]\n",
        "\n",
        "  x, y, a = get_batch(\"train\")\n",
        "  optim.zero_grad()\n",
        "  with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "    logits = model(x, attention_mask = a).logits\n",
        "    loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  # lri.append(lre[step])\n",
        "  # lossi.append(loss.item())\n",
        "  if step % 100 == 0:\n",
        "    losses = estimate_loss(200)\n",
        "    print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['validation']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd85db9a9e0>]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lri, lossi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "07M0Elr_5-ZE"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import f1_score, recall_score, precision_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_model(split=\"test\"):\n",
        "    \"\"\"Evaluate model performance on given split with seqeval metrics\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    if split == \"test\":\n",
        "        data_input_ids = test_data\n",
        "        data_labels = test_labels\n",
        "        data_attention_mask = test_attention_mask\n",
        "    elif split == \"validation\":\n",
        "        data_input_ids = val_data\n",
        "        data_labels = val_labels\n",
        "        data_attention_mask = val_attention_mask\n",
        "    else:\n",
        "        data_input_ids = train_data\n",
        "        data_labels = train_labels\n",
        "        data_attention_mask = train_attention_mask\n",
        "    \n",
        "    # Process in smaller batches to avoid OOM\n",
        "    batch_size_eval = 16\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "    \n",
        "    # Process the entire dataset\n",
        "    for i in tqdm(range(0, len(data_input_ids), batch_size_eval), desc=f\"Evaluating on {split}\"):\n",
        "        # Get batch\n",
        "        batch_input_ids = torch.tensor(data_input_ids[i:i+batch_size_eval]).to(device)\n",
        "        batch_labels = torch.tensor(data_labels[i:i+batch_size_eval]).to(device)\n",
        "        batch_attention_mask = torch.tensor(data_attention_mask[i:i+batch_size_eval]).to(device)\n",
        "        \n",
        "        # Get predictions\n",
        "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        \n",
        "        # Convert predictions and labels to lists for seqeval\n",
        "        for j in range(len(batch_input_ids)):\n",
        "            true_label_ids = batch_labels[j].cpu().numpy()\n",
        "            pred_label_ids = predictions[j].cpu().numpy()\n",
        "            \n",
        "            # Convert IDs to labels, handling special tokens\n",
        "            true_seq = []\n",
        "            pred_seq = []\n",
        "            \n",
        "            for true_id, pred_id, mask in zip(true_label_ids, pred_label_ids, batch_attention_mask[j]):\n",
        "                if mask == 1 and true_id != -100:  # Only evaluate on non-padding and non-special tokens\n",
        "                    true_seq.append(itol[true_id.item()])\n",
        "                    pred_seq.append(itol[pred_id.item()])\n",
        "            \n",
        "            if true_seq:  # Only add if not empty\n",
        "                all_true_labels.append(true_seq)\n",
        "                all_pred_labels.append(pred_seq)\n",
        "    \n",
        "    # Calculate metrics using seqeval\n",
        "    precision = precision_score(all_true_labels, all_pred_labels)\n",
        "    recall = recall_score(all_true_labels, all_pred_labels)\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels)\n",
        "    report = classification_report(all_true_labels, all_pred_labels)\n",
        "    \n",
        "    print(f\"\\n=== Evaluation on {split} split ===\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(report)\n",
        "    \n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"report\": report\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating on test: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation on test split ===\n",
            "F1 Score: 0.8542\n",
            "Precision: 0.8262\n",
            "Recall: 0.8843\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AC       0.88      0.90      0.89       797\n",
            "          LF       0.74      0.85      0.80       482\n",
            "\n",
            "   micro avg       0.83      0.88      0.85      1279\n",
            "   macro avg       0.81      0.88      0.84      1279\n",
            "weighted avg       0.83      0.88      0.86      1279\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "out = evaluate_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating on val: 100%|██████████| 125/125 [00:27<00:00,  4.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation on val split ===\n",
            "F1 Score: 0.9306\n",
            "Precision: 0.9024\n",
            "Recall: 0.9606\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AC       0.92      0.97      0.94      6626\n",
            "          LF       0.88      0.95      0.91      3923\n",
            "\n",
            "   micro avg       0.90      0.96      0.93     10549\n",
            "   macro avg       0.90      0.96      0.93     10549\n",
            "weighted avg       0.90      0.96      0.93     10549\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'f1': 0.93057213701901,\n",
              " 'precision': 0.9023955828657939,\n",
              " 'recall': 0.9605649824627926,\n",
              " 'report': '              precision    recall  f1-score   support\\n\\n          AC       0.92      0.97      0.94      6626\\n          LF       0.88      0.95      0.91      3923\\n\\n   micro avg       0.90      0.96      0.93     10549\\n   macro avg       0.90      0.96      0.93     10549\\nweighted avg       0.90      0.96      0.93     10549\\n'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
