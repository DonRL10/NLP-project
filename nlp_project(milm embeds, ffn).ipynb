{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e962acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5eeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518209f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"O\", \"B-AC\", \"B-LF\", \"I-LF\"]\n",
    "n_labels = len(labels)\n",
    "ltoi = {l: i for i, l in enumerate(labels)}\n",
    "itol = {i: l for l, i in ltoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb97fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb811fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeds(examples):\n",
    "    encoded_input = tokenizer(examples['tokens'], padding=True, truncation=True, return_tensors='pt', is_split_into_words=True)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1b4edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True, # Crucial for pre-tokenized input\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label_sequence in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None: # Special tokens ([CLS], [SEP])\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx: # First token of a new word\n",
    "                label_ids.append(ltoi[label_sequence[word_idx]])\n",
    "            else: # Subsequent tokens of the same word\n",
    "                label_ids.append(-100)\n",
    "\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f0ef6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c56a0f67a34ed8b628f02159e15908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9028ccd9202943f38e740dd73cd44f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f258e3fc8f49d78006b505d078b73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = dataset.map(tokenize_and_align_labels, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54caf7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, train_attention_mask = data['train']['input_ids'], data['train']['labels'], data['train']['attention_mask']\n",
    "val_data, val_labels, val_attention_mask = data['validation']['input_ids'], data['validation']['labels'], data['validation']['attention_mask']\n",
    "test_data, test_labels, test_attention_mask = data['test']['input_ids'], data['test']['labels'], data['test']['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e83db9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8\n",
    "\n",
    "def get_batch(split = \"train\"):\n",
    "  data = train_data if split == \"train\" else val_data\n",
    "  labels = train_labels if split == \"train\" else val_labels\n",
    "  attention_mask = train_attention_mask if split == \"train\" else val_attention_mask\n",
    "  ix = torch.randint(len(data), (batch_size,))\n",
    "  x = torch.stack([torch.tensor(data[i]).long() for i in ix])\n",
    "  y = torch.stack([torch.tensor(labels[i]).long() for i in ix])\n",
    "  a = torch.stack([torch.tensor(attention_mask[i]) for i in ix])\n",
    "  return x.to(device), y.to(device), a.to(device)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_steps):\n",
    "  out = {}\n",
    "  model_ffn.eval()\n",
    "  for split in [\"train\", \"validation\"]:\n",
    "    losses = torch.zeros(eval_steps)\n",
    "    for k in range(eval_steps):\n",
    "      x, y, a = get_batch(split)\n",
    "      logits = model_ffn(x, attention_mask = a)\n",
    "      loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "      losses[k] = loss.item()\n",
    "    out[split] = losses.mean()\n",
    "  model_ffn.train()\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e40c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "242e0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLM_FFN(nn.Module):\n",
    "    def __init__(self, model, dim, n_labels):\n",
    "        super().__init__()\n",
    "        self.minilm = model\n",
    "        self.n_emb = model.config.hidden_size # Should be 384\n",
    "\n",
    "        \n",
    "        for param in self.minilm.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(self.n_emb, dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(dim, n_labels)\n",
    "\n",
    "    def forward(self, idxs, attention_mask):\n",
    "        # Get MiniLM embeddings\n",
    "        # outputs.last_hidden_state shape: (batch_size, seq_len, minilm_embedding_dim)\n",
    "        x = self.minilm(input_ids=idxs, attention_mask=attention_mask)\n",
    "        tok_embs = x.last_hidden_state\n",
    "\n",
    "        # Apply FFN\n",
    "        x = self.fc1(tok_embs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc2(x) # (batch_size, seq_len, num_labels)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c560e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e63727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffn = MiniLM_FFN(model, 256, 4).to(device)\n",
    "model_ffn = torch.compile(model_ffn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5249a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optim = torch.optim.AdamW(model_ffn.parameters(), lr = 1e-3)\n",
    "max_steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d72de386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/5000 [00:05<22:22,  3.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.2960, val loss 1.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 526/5000 [00:15<06:41, 11.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 500: train loss 0.4412, val loss 0.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1021/5000 [00:24<05:58, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: train loss 0.3733, val loss 0.4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 1529/5000 [00:34<05:13, 11.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500: train loss 0.3567, val loss 0.4624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2020/5000 [00:43<04:29, 11.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000: train loss 0.3456, val loss 0.4381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2521/5000 [00:53<03:49, 10.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2500: train loss 0.3166, val loss 0.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3018/5000 [01:03<03:09, 10.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000: train loss 0.3016, val loss 0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 3518/5000 [01:12<02:20, 10.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3500: train loss 0.2928, val loss 0.4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4017/5000 [01:22<01:32, 10.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000: train loss 0.2831, val loss 0.4476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 4524/5000 [01:31<00:46, 10.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4500: train loss 0.2718, val loss 0.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:35<00:00, 52.54it/s] \n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "lri = []\n",
    "\n",
    "for step in tqdm(range(max_steps)):\n",
    "  # for g in optim.param_groups:\n",
    "  #   g['lr'] = lrs[step]\n",
    "\n",
    "  x, y, a = get_batch(\"train\")\n",
    "  optim.zero_grad()\n",
    "  with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "    logits = model_ffn(x, attention_mask = a)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "  loss.backward()\n",
    "  optim.step()\n",
    "  # lri.append(lre[step])\n",
    "  # lossi.append(loss.item())\n",
    "  if step % 500 == 0:\n",
    "    losses = estimate_loss(200)\n",
    "    print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['validation']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "881438e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c4600fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(split=\"test\"):\n",
    "    \"\"\"Evaluate model performance on given split with seqeval metrics\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    if split == \"test\":\n",
    "        data_input_ids = test_data\n",
    "        data_labels = test_labels\n",
    "        data_attention_mask = test_attention_mask\n",
    "    elif split == \"validation\":\n",
    "        data_input_ids = val_data\n",
    "        data_labels = val_labels\n",
    "        data_attention_mask = val_attention_mask\n",
    "    else:\n",
    "        data_input_ids = train_data\n",
    "        data_labels = train_labels\n",
    "        data_attention_mask = train_attention_mask\n",
    "    \n",
    "    # Process in smaller batches to avoid OOM\n",
    "    batch_size_eval = 16\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    \n",
    "    # Process the entire dataset\n",
    "    for i in tqdm(range(0, len(data_input_ids), batch_size_eval), desc=f\"Evaluating on {split}\"):\n",
    "        # Get batch\n",
    "        batch_input_ids = torch.tensor(data_input_ids[i:i+batch_size_eval]).to(device)\n",
    "        batch_labels = torch.tensor(data_labels[i:i+batch_size_eval]).to(device)\n",
    "        batch_attention_mask = torch.tensor(data_attention_mask[i:i+batch_size_eval]).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = model_ffn(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # Convert predictions and labels to lists for seqeval\n",
    "        for j in range(len(batch_input_ids)):\n",
    "            true_label_ids = batch_labels[j].cpu().numpy()\n",
    "            pred_label_ids = predictions[j].cpu().numpy()\n",
    "            \n",
    "            # Convert IDs to labels, handling special tokens\n",
    "            true_seq = []\n",
    "            pred_seq = []\n",
    "            \n",
    "            for true_id, pred_id, mask in zip(true_label_ids, pred_label_ids, batch_attention_mask[j]):\n",
    "                if mask == 1 and true_id != -100:  # Only evaluate on non-padding and non-special tokens\n",
    "                    true_seq.append(itol[true_id.item()])\n",
    "                    pred_seq.append(itol[pred_id.item()])\n",
    "            \n",
    "            if true_seq:  # Only add if not empty\n",
    "                all_true_labels.append(true_seq)\n",
    "                all_pred_labels.append(pred_seq)\n",
    "    \n",
    "    # Calculate metrics using seqeval\n",
    "    precision = precision_score(all_true_labels, all_pred_labels)\n",
    "    recall = recall_score(all_true_labels, all_pred_labels)\n",
    "    f1 = f1_score(all_true_labels, all_pred_labels)\n",
    "    report = classification_report(all_true_labels, all_pred_labels)\n",
    "    \n",
    "    print(f\"\\n=== Evaluation on {split} split ===\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"report\": report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37836d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on test split ===\n",
      "F1 Score: 0.4796\n",
      "Precision: 0.4169\n",
      "Recall: 0.5645\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.75      0.75      0.75       797\n",
      "          LF       0.13      0.26      0.17       482\n",
      "\n",
      "   micro avg       0.42      0.56      0.48      1279\n",
      "   macro avg       0.44      0.50      0.46      1279\n",
      "weighted avg       0.52      0.56      0.53      1279\n",
      "\n",
      "{'f1': 0.4795748920624377, 'precision': 0.4168591224018476, 'recall': 0.5645035183737295, 'report': '              precision    recall  f1-score   support\\n\\n          AC       0.75      0.75      0.75       797\\n          LF       0.13      0.26      0.17       482\\n\\n   micro avg       0.42      0.56      0.48      1279\\n   macro avg       0.44      0.50      0.46      1279\\nweighted avg       0.52      0.56      0.53      1279\\n'}\n"
     ]
    }
   ],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec8b5865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on validation split ===\n",
      "F1 Score: 0.4783\n",
      "Precision: 0.4160\n",
      "Recall: 0.5627\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.75      0.75      0.75       508\n",
      "          LF       0.13      0.25      0.17       306\n",
      "\n",
      "   micro avg       0.42      0.56      0.48       814\n",
      "   macro avg       0.44      0.50      0.46       814\n",
      "weighted avg       0.51      0.56      0.53       814\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.4783289817232376,\n",
       " 'precision': 0.4159854677565849,\n",
       " 'recall': 0.5626535626535627,\n",
       " 'report': '              precision    recall  f1-score   support\\n\\n          AC       0.75      0.75      0.75       508\\n          LF       0.13      0.25      0.17       306\\n\\n   micro avg       0.42      0.56      0.48       814\\n   macro avg       0.44      0.50      0.46       814\\nweighted avg       0.51      0.56      0.53       814\\n'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "643bf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(examples):\n",
    "    labels = []\n",
    "    for i, label_sequence in enumerate(examples[\"ner_tags\"]):\n",
    "        encoded = [ltoi[k] for k in label_sequence]\n",
    "        labels.append(torch.tensor(encoded).long())\n",
    "    encoded = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf0ed0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = compute_embeds(dataset['train'])\n",
    "val_data = compute_embeds(dataset['validation'])\n",
    "test_data = compute_embeds(dataset['test'])\n",
    "\n",
    "train_labels = labels(dataset['train'])\n",
    "val_labels = labels(dataset['validation'])\n",
    "test_labels = labels(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2574f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8\n",
    "\n",
    "def get_batch(split = \"train\"):\n",
    "  data = train_data if split == \"train\" else val_data\n",
    "  labels = train_labels if split =='train' else val_labels\n",
    "  ix = torch.randint(len(data), (batch_size,))\n",
    "  x = torch.stack([torch.tensor(data[i]).long() for i in ix])\n",
    "  y = torch.stack([torch.tensor(labels[i]).long() for i in ix])\n",
    "  return x.to(device), y.to(device), \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_steps):\n",
    "  out = {}\n",
    "  model.eval()\n",
    "  for split in [\"train\", \"validation\"]:\n",
    "    losses = torch.zeros(eval_steps)\n",
    "    for k in range(eval_steps):\n",
    "      x, y = get_batch(split)\n",
    "      logits, loss = model(x, y)\n",
    "      losses[k] = loss.item()\n",
    "    out[split] = losses.mean()\n",
    "  model.train()\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc78f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f7a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
